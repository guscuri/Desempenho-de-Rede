{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1c7567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports Essenciais ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from IPython.display import HTML # Para exibir a anima√ß√£o no notebook\n",
    "\n",
    "\n",
    "# --- Configura√ß√µes de Estilo e Avisos ---\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.style.use('seaborn-v0_8-whitegrid') # Deixa os gr√°ficos mais bonitos\n",
    "\n",
    "print(\"Bibliotecas importadas com sucesso.\")\n",
    "\n",
    "# --- Defini√ß√£o das Bandas Contratadas (em bps) ---\n",
    "BANDAS_ESPECIFICAS = {\n",
    "    'dc:a6:32:6b:9a:da': 500_000_000, \n",
    "    'dc:a6:32:6b:9c:a8': 600_000_000,\n",
    "    'e4:5f:01:ad:56:31': 350_000_000,\n",
    "    'e4:5f:01:36:10:3e': 1_000_000_000,\n",
    "    'e4:5f:01:8e:52:7a': 1_000_000_000,\n",
    "    'e4:5f:01:b4:bb:d4': 750_000_000,\n",
    "    '80:af:ca:27:f3:0e': 1_000_000_000,\n",
    "    '98:25:4a:b9:46:23': 1_000_000_000\n",
    "}\n",
    "BANDA_PADRAO = 100_000_000 # Valor padr√£o se um MAC n√£o estiver na lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d13d64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa o CSV e transforma em DataFrame\n",
    "df = pd.read_csv('ndt_tests_att.csv')\n",
    "\n",
    "# Agrupar dados por pares de MAC address e server IP\n",
    "pares_unicos = df.groupby(['mac_address', 'server_ip']).size().reset_index(name='count')\n",
    "print(f\"Total de pares √∫nicos: {len(pares_unicos)}\")\n",
    "print(f\"Total de registros: {pares_unicos['count'].sum()}\")\n",
    "# Exibir estat√≠sticas por par\n",
    "print(\"\\nEstat√≠sticas por par:\")\n",
    "\n",
    "# Ordena os pares por n√∫mero de registros (do maior para o menor)\n",
    "pares_ordenados = pares_unicos.sort_values('count', ascending=False)\n",
    "pares_ordenados = pares_ordenados[pares_ordenados['count'] >= 70]\n",
    "print(len(pares_ordenados), \"pares com pelo menos 70 registros.\")\n",
    "# Filtrar o DataFrame para manter apenas os pares selecionados\n",
    "pares_selecionados = pares_ordenados[['mac_address', 'server_ip']]\n",
    "df = df.merge(pares_selecionados, on=['mac_address', 'server_ip'], how='inner')\n",
    "df = df.drop(columns=['download_retrans_percent', 'test_uuid', 'client_ip'])\n",
    "\n",
    "# Filtrando timestamps\n",
    "# Converte e filtra o timestamp\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s')\n",
    "df = df[df['timestamp'] >= '2025-05-28']\n",
    "TIMESTAMPS_PARA_REMOVER = [\n",
    "    '2025-06-18 15:29:04',\n",
    "    '2025-07-13 01:09:40',\n",
    "    '2025-06-09 21:08:31',\n",
    "    '2025-06-08 13:12:10',\n",
    "    '2025-06-30 19:47:38',\n",
    "    '2025-07-09 00:08:06',\n",
    "    '2025-06-20 21:29:28',\n",
    "    '2025-07-06 12:50:32',\n",
    "    '2025-06-25 03:59:45',\n",
    "    '2025-06-16 03:22:18',\n",
    "    '2025-07-08 19:51:17',\n",
    "    '2025-07-10 01:15:49',\n",
    "    '2025-06-16 09:15:57',\n",
    "    '2025-06-30 00:31:50',\n",
    "    '2025-06-08 15:12:18',\n",
    "    '2025-05-29 04:13:34',\n",
    "    '2025-05-29 09:04:43',\n",
    "    '2025-05-29 13:21:28',\n",
    "    '2025-05-30 04:14:04',\n",
    "    '2025-07-03 20:50:39',\n",
    "    '2025-05-28 17:36:20',\n",
    "    '2025-05-28 18:22:46',\n",
    "    '2025-05-28 18:52:46',\n",
    "    '2025-05-28 20:52:46',\n",
    "    '2025-05-28 22:21:29',\n",
    "    '2025-05-29 00:32:56',\n",
    "    '2025-05-29 01:43:34',\n",
    "    '2025-05-29 03:43:34',\n",
    "    '2025-05-29 04:43:34',\n",
    "    '2025-05-29 05:55:28',\n",
    "    '2025-05-29 07:23:55',\n",
    "    '2025-05-29 07:56:51',\n",
    "    '2025-05-29 10:52:49',\n",
    "    '2025-05-29 11:31:45',\n",
    "    '2025-05-29 12:13:43',\n",
    "    '2025-05-29 14:26:56',\n",
    "    '2025-05-29 16:55:14',\n",
    "    '2025-05-29 18:07:22',\n",
    "    '2025-05-29 20:37:22',\n",
    "    '2025-05-29 22:44:27',\n",
    "    '2025-05-29 23:59:48',\n",
    "    '2025-05-30 02:14:03',\n",
    "    '2025-05-30 04:44:04',\n",
    "    '2025-05-30 05:55:06',\n",
    "    '2025-05-30 06:51:39',\n",
    "    '2025-05-30 08:01:50',\n",
    "    '2025-05-30 09:51:51',\n",
    "    '2025-05-30 11:20:22',\n",
    "    '2025-05-30 12:55:19',\n",
    "    '2025-05-30 13:25:18',\n",
    "    '2025-05-30 14:14:04',\n",
    "    '2025-05-30 15:25:18',\n",
    "    '2025-05-30 16:47:34',\n",
    "    '2025-05-30 17:36:20',\n",
    "    '2025-05-30 18:22:46',\n",
    "    '2025-05-30 19:52:46',\n",
    "    '2025-05-30 20:47:34',\n",
    "    '2025-05-30 21:52:46',\n",
    "    '2025-05-30 22:20:34',\n",
    "    '2025-05-30 23:21:29',\n",
    "    '2025-05-30 00:29:49',\n",
    "    '2025-06-11 00:48:09',\n",
    "    '2025-05-29 15:26:56',\n",
    "    '2025-05-29 18:37:22',\n",
    "    '2025-05-29 22:14:27',\n",
    "    '2025-06-14 22:12:41',\n",
    "    '2025-06-20 18:43:39',\n",
    "    '2025-05-30 14:35:13',\n",
    "    '2025-06-20 16:28:57',\n",
    "    '2025-06-13 01:29:47',\n",
    "    '2025-06-14 20:25:06',\n",
    "    '2025-06-07 08:56:58',\n",
    "    '2025-06-15 12:46:22',\n",
    "    '2025-06-01 04:04:52',\n",
    "    '2025-06-03 13:13:52',\n",
    "    '2025-06-13 19:31:36',\n",
    "    '2025-06-14 15:25:58',\n",
    "    '2025-06-01 01:25:24',\n",
    "    '2025-06-01 21:31:57',\n",
    "    '2025-06-12 14:21:41',\n",
    "    '2025-06-14 13:56:40',\n",
    "    '2025-06-09 13:10:41',\n",
    "    '2025-07-01 21:34:28',\n",
    "    '2025-06-12 16:08:21',\n",
    "    '2025-06-15 17:46:23',\n",
    "    '2025-06-08 06:58:23',\n",
    "    '2025-06-01 10:07:15',\n",
    "    '2025-06-18 19:00:00',\n",
    "    '2025-06-18 20:30:00',\n",
    "    '2025-06-02 22:01:43',\n",
    "    '2025-06-11 10:12:07',\n",
    "    '2025-07-07 15:05:46',\n",
    "    '2025-07-03 21:27:08',\n",
    "    '2025-06-09 15:42:42',\n",
    "    '2025-06-22 02:23:29',\n",
    "    '2025-06-22 16:23:31',\n",
    "    '2025-06-26 04:33:53',\n",
    "    '2025-06-22 07:47:41',\n",
    "    '2025-07-08 22:37:40',\n",
    "    '2025-06-04 04:40:07',\n",
    "    '2025-06-09 16:27:46',\n",
    "    '2025-07-03 02:30:52',\n",
    "    '2025-06-15 22:00:18',\n",
    "    '2025-06-07 13:42:10',\n",
    "    '2025-06-21 13:07:05',\n",
    "    '2025-07-08 05:16:07',\n",
    "    '2025-06-20 17:28:58',\n",
    "    '2025-06-22 05:47:41',\n",
    "    '2025-06-05 19:27:26',\n",
    "    '2025-06-12 18:55:08',\n",
    "    '2025-06-02 10:55:00',\n",
    "    '2025-06-11 19:43:45',\n",
    "    '2025-07-05 02:49:47',\n",
    "    '2025-06-23 19:54:06',\n",
    "    '2025-06-27 21:39:32',\n",
    "    '2025-07-09 02:08:10',\n",
    "    '2025-06-12 15:52:24',\n",
    "    '2025-07-04 01:47:41',\n",
    "    '2025-06-03 18:57:50',\n",
    "    '2025-07-04 21:10:10',\n",
    "    '2025-07-07 23:30:04',\n",
    "    '2025-06-15 23:01:53',\n",
    "    '2025-06-04 01:35:48'\n",
    "]\n",
    "timestamps_removidos = pd.to_datetime(TIMESTAMPS_PARA_REMOVER)\n",
    "indices_para_remover = df[df['timestamp'].isin(timestamps_removidos)].index\n",
    "df.drop(indices_para_remover, inplace=True) # Remove do DataFrame principal 'df'\n",
    "\n",
    "# AJUSTE: Garante que os dados est√£o ordenados por tempo\n",
    "df = df.sort_values(by='timestamp')\n",
    "\n",
    "# Resetar o √≠ndice caso ele j√° exista de algum passo anterior\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(\"DataFrame preparado e pronto para an√°lise:\")\n",
    "print(df.head())\n",
    "print(f\"\\nTotal de pontos ap√≥s a filtragem: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688203f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar uma figura com subplots para todos os pares analisados\n",
    "fig, axes = plt.subplots(5, 5, figsize=(20, 16))\n",
    "fig.suptitle('Dados de Download Throughput para Todos os Pares Analisados', fontsize=20, y=0.98)\n",
    "\n",
    "# Achatar a matriz de eixos para itera√ß√£o mais f√°cil\n",
    "axes_flat = axes.flatten()\n",
    "\n",
    "# Iterar pelos pares para an√°lise\n",
    "for idx, (_, linha_par) in enumerate(pares_para_analise.iterrows()):\n",
    "    if idx >= 36:  # Limitamos a 36 pares (6x6 grid)\n",
    "        break\n",
    "        \n",
    "    mac = linha_par['mac_address']\n",
    "    server = linha_par['server_ip']\n",
    "    \n",
    "    # Filtrar dados para o par atual\n",
    "    dados_par = df[(df['mac_address'] == mac) & (df['server_ip'] == server)]\n",
    "    \n",
    "    # Plotar no subplot correspondente\n",
    "    ax = axes_flat[idx]\n",
    "    ax.plot(dados_par['timestamp'], dados_par['download_tp_bps'] / 1e9, 'b.', alpha=0.7, markersize=5)\n",
    "    \n",
    "    # Formata√ß√£o do subplot\n",
    "    ax.set_title(f'{mac}‚Üí{server}', fontsize=8)\n",
    "    ax.set_ylabel('Download (Gbps)', fontsize=8)\n",
    "    ax.tick_params(axis='x', rotation=45, labelsize=6)\n",
    "    ax.tick_params(axis='y', labelsize=6)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Remover subplots vazios se houver menos de 25 pares\n",
    "for idx in range(len(pares_para_analise), 25):\n",
    "    axes_flat[idx].remove()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.94)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Plotados {min(len(pares_para_analise), 25)} pares de {len(pares_para_analise)} dispon√≠veis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab8ce8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================\n",
    "# ABORDAGEM 1: MODELO ARX (EQUA√á√ÉO DE DIFEREN√áAS)\n",
    "# ==================================================================\n",
    "\n",
    "def estimar_coeficientes_arx(grupo_df):\n",
    "    \"\"\"\n",
    "    Prepara os dados com colunas 'futuras' e estima os coeficientes do modelo ARX\n",
    "    usando Regress√£o Linear.\n",
    "    \"\"\"\n",
    "    # Define as 'causas' (features) e o 'efeito' (alvo)\n",
    "    features = ['download_tp_bps', 'latency_download_sec', 'upload_tp_bps', 'latency_upload_sec']\n",
    "    alvo = 'download_tp_bps' # Queremos prever o pr√≥ximo download\n",
    "    \n",
    "    df_modelo = grupo_df[features].copy()\n",
    "    \n",
    "    # Cria a coluna alvo com o valor do pr√≥ximo passo usando .shift(-1)\n",
    "    df_modelo['alvo_futuro'] = df_modelo[alvo].shift(-1)\n",
    "    \n",
    "    # Remove a √∫ltima linha que n√£o tem um valor futuro\n",
    "    df_modelo.dropna(inplace=True)\n",
    "    \n",
    "    if len(df_modelo) < 10: # A regress√£o precisa de alguns pontos para garantir uma boa estimativa\n",
    "        return None\n",
    "\n",
    "    # Prepara os dados para a regress√£o\n",
    "    X = df_modelo[features]\n",
    "    y = df_modelo['alvo_futuro']\n",
    "    \n",
    "    # Usamos a regress√£o linear da scikit-learn para encontrar os coeficientes\n",
    "    reg = LinearRegression()\n",
    "    reg.fit(X, y)\n",
    "    \n",
    "    # Retorna o intercepto (c0) e os outros coeficientes (c1, c2...)\n",
    "    return {'intercepto': reg.intercept_, 'coeficientes': reg.coef_}\n",
    "\n",
    "def simular_e_plotar_arx(par, dados_reais_par, resultado_arx):\n",
    "    \"\"\"\n",
    "    Simula o modelo ARX passo a passo e plota o resultado.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Gerando Simula√ß√£o ARX para o Par: {par} ---\")\n",
    "    \n",
    "    # Pega os coeficientes encontrados\n",
    "    intercepto = resultado_arx['intercepto']\n",
    "    coeficientes = resultado_arx['coeficientes']\n",
    "    \n",
    "    # Usa a primeira linha de dados como ponto de partida da simula√ß√£o\n",
    "    estado_atual = dados_reais_par.iloc[0][['download_tp_bps', 'latency_download_sec', 'upload_tp_bps', 'latency_upload_sec']].to_numpy()\n",
    "    previsoes = [estado_atual[0]] # Come√ßa com o primeiro valor real de download\n",
    "    \n",
    "    # Loop de simula√ß√£o: prev√™ um passo de cada vez\n",
    "    for i in range(len(dados_reais_par) - 1):\n",
    "        # A equa√ß√£o de diferen√ßas: D[n+1] = c0 + c1*D[n] + c2*L_D[n] + ...\n",
    "        previsao_proximo_d = intercepto + np.dot(estado_atual, coeficientes)\n",
    "        previsoes.append(previsao_proximo_d)\n",
    "        \n",
    "        # Atualiza o estado para a pr√≥xima itera√ß√£o\n",
    "        # Usamos a previs√£o para o download e os valores reais para as outras vari√°veis\n",
    "        estado_atual = dados_reais_par.iloc[i+1][['download_tp_bps', 'latency_download_sec', 'upload_tp_bps', 'latency_upload_sec']].to_numpy()\n",
    "        estado_atual[0] = previsao_proximo_d\n",
    "\n",
    "    # Plotagem\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.plot(dados_reais_par['timestamp'], dados_reais_par['download_tp_bps'], 'o', alpha=0.6, label='Download Real')\n",
    "    plt.plot(dados_reais_par['timestamp'], previsoes, 'r.-', alpha=0.8, label='Simula√ß√£o do Modelo ARX')\n",
    "    plt.title(f\"Valida√ß√£o do Modelo ARX para o Par {par}\", fontsize=16)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232f5c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar dados para o par espec√≠fico\n",
    "par_especifico = df[(df['mac_address'] == 'e4:5f:01:b4:bb:d4') & (df['server_ip'] == '200.159.254.239')]\n",
    "\n",
    "# Plotar os dados reais\n",
    "plt.figure(figsize=(16, 10))\n",
    "\n",
    "# Subplot 1: Download throughput\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(par_especifico['timestamp'], par_especifico['download_tp_bps'], 'b.-', alpha=0.7)\n",
    "plt.title('Download Throughput')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Download (bps)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.suptitle(f\"Dados Reais para MAC: dc:a6:32:6b:9a:da -> Server: 177.136.80.229\\nTotal de pontos: {len(par_especifico)}\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Estat√≠sticas do par:\")\n",
    "print(f\"N√∫mero de registros: {len(par_especifico)}\")\n",
    "print(f\"Per√≠odo: {par_especifico['timestamp'].min()} at√© {par_especifico['timestamp'].max()}\")\n",
    "# Encontrar o menor valor de download e seu timestamp\n",
    "min_download = par_especifico['download_tp_bps'].min()\n",
    "min_timestamp = par_especifico.loc[par_especifico['download_tp_bps'].idxmin(), 'timestamp']\n",
    "\n",
    "print(f\"Menor valor de download: {min_download:,.2f} bps\")\n",
    "print(f\"Timestamp do menor valor: {min_timestamp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b63c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================\n",
    "# BLOCO DE EXECU√á√ÉO FINAL (CORRIGIDO)\n",
    "# ==================================================================\n",
    "\n",
    "print(\"Iniciando an√°lise com o Modelo ARX para os pares selecionados...\")\n",
    "\n",
    "# Pega a lista de pares √∫nicos que voc√™ j√° filtrou (com 70+ registros)\n",
    "print(f\"Total de pontos para an√°lise: {len(df)}\")\n",
    "pares_para_analise = df.groupby(['mac_address', 'server_ip']).size().reset_index(name='count')\n",
    "pares_para_analise = pares_para_analise[pares_para_analise['count'] >= 69]\n",
    "print(f\"Total de pares para an√°lise: {len(pares_para_analise)}\")\n",
    "# --- AQUI EST√Å O LOOP CORRIGIDO ---\n",
    "\n",
    "# Usamos .iterrows() para iterar sobre as linhas do DataFrame de pares\n",
    "for index, linha_par in pares_para_analise.iterrows():\n",
    "    \n",
    "    # Pega o mac e o server da linha atual\n",
    "    mac = linha_par['mac_address']\n",
    "    server = linha_par['server_ip']\n",
    "    par = (mac, server)\n",
    "    \n",
    "    # Agora, filtra o DataFrame principal para pegar o grupo de dados deste par\n",
    "    # Lembre-se de usar seu DataFrame limpo (df_limpo) aqui, se tiver um.\n",
    "    grupo_df = df[(df['mac_address'] == mac) & (df['server_ip'] == server)]\n",
    "    \n",
    "    # 1. Estima os coeficientes para o par atual\n",
    "    # A fun√ß√£o 'estimar_coeficientes_arx' recebe o grupo de dados correto\n",
    "    resultado_arx = estimar_coeficientes_arx(grupo_df)\n",
    "    \n",
    "    # 2. Se a estima√ß√£o foi bem sucedida, simula e plota\n",
    "    if resultado_arx:\n",
    "        print(f\"Coeficientes encontrados para {par}:\")\n",
    "        print(f\"  Intercepto (c0): {resultado_arx['intercepto']:.2f}\")\n",
    "        print(f\"  Coeficientes (c1..c4): {resultado_arx['coeficientes']}\")\n",
    "        simular_e_plotar_arx(par, grupo_df, resultado_arx)\n",
    "    else:\n",
    "        print(f\"  ‚ùå Falha na estima√ß√£o dos coeficientes para {par} (dados insuficientes)\")\n",
    "\n",
    "# Contador de gr√°ficos gerados\n",
    "if 'resultado_arx' in locals() and resultado_arx:\n",
    "    graficos_gerados = sum(1 for _, linha in pares_para_analise.iterrows() \n",
    "                            if estimar_coeficientes_arx(df[(df['mac_address'] == linha['mac_address']) & \n",
    "                                                        (df['server_ip'] == linha['server_ip'])]) is not None)\n",
    "    print(f\"\\nüìä Total de gr√°ficos ARX gerados: {graficos_gerados}\")\n",
    "print(\"\\nAn√°lise ARX finalizada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf88561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Defini√ß√£o da Classe para o Filtro RLS ---\n",
    "class FiltroRLS:\n",
    "    \"\"\"\n",
    "    Implementa um filtro Recursive Least Squares (RLS) para aprendizado online.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_variaveis, fator_esquecimento=0.99, P_inicial=1e6):\n",
    "        self.num_vars = num_variaveis\n",
    "        self.lam = fator_esquecimento\n",
    "        self.theta = np.zeros(num_variaveis)\n",
    "        self.P = P_inicial * np.identity(num_variaveis)\n",
    "\n",
    "    def update(self, x, y):\n",
    "        x = np.asarray(x).reshape(self.num_vars, 1)\n",
    "        y = np.asarray(y)\n",
    "        erro_previsao = y - (x.T @ self.theta)\n",
    "        Px = self.P @ x\n",
    "        ganho_k = Px / (self.lam + x.T @ Px)\n",
    "        self.theta = self.theta + (ganho_k * erro_previsao).flatten()\n",
    "        self.P = (1 / self.lam) * (self.P - (ganho_k @ x.T @ self.P))\n",
    "\n",
    "    def predict(self, x):\n",
    "        return np.dot(x, self.theta)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1691e65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_animacao_rls(df, mac_alvo, server_alvo, fator_esquecimento=0.995):\n",
    "    \"\"\"\n",
    "    Gera e salva uma anima√ß√£o do processo de aprendizado RLS com escalas de gr√°fico aprimoradas.\n",
    "    \"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Iniciando gera√ß√£o de anima√ß√£o para o par: {(mac_alvo, server_alvo)}\")\n",
    "\n",
    "    # 1. Prepara√ß√£o dos Dados\n",
    "    dados_par = df[(df['mac_address'] == mac_alvo) & (df['server_ip'] == server_alvo)].sort_values(by='timestamp')\n",
    "    if len(dados_par) < 20:\n",
    "        print(\"--> DADOS INSUFICIENTES.\")\n",
    "        return None\n",
    "    \n",
    "    df_modelo = dados_par[['download_tp_bps', 'latency_download_sec', 'upload_tp_bps', 'latency_upload_sec']].copy()\n",
    "    df_modelo['D_proximo'] = df_modelo['download_tp_bps'].shift(-1)\n",
    "    df_modelo.dropna(inplace=True)\n",
    "    df_modelo.insert(0, 'intercept', 1)\n",
    "    \n",
    "    X = df_modelo[['intercept', 'download_tp_bps', 'latency_download_sec', 'upload_tp_bps', 'latency_upload_sec']].to_numpy()\n",
    "    y = df_modelo['D_proximo'].to_numpy()\n",
    "\n",
    "    # 2. Inicializa√ß√£o do Filtro e Hist√≥ricos\n",
    "    num_coeficientes = X.shape[1]\n",
    "    filtro = FiltroRLS(num_variaveis=num_coeficientes, fator_esquecimento=fator_esquecimento)\n",
    "    historico_coeficientes = []\n",
    "    historico_erro = []\n",
    "    previsoes_online = []\n",
    "\n",
    "    # 3. Configura√ß√£o da Figura\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(18, 10), gridspec_kw={'height_ratios': [3, 2]})\n",
    "    mac_formatado = mac_alvo.replace(':', '')\n",
    "    # Depois, usamos essa vari√°vel j√° limpa na f-string\n",
    "    fig.suptitle(f'Aprendizado Online (RLS) para {mac_formatado} -> {server_alvo}', fontsize=18)\n",
    "\n",
    "    \n",
    "    ax1 = axs[0, 0]; ax2 = axs[0, 1]; ax3 = axs[1, 0]; ax4 = axs[1, 1]\n",
    "    ax1.plot(range(len(y)), y, 'o', color='skyblue', alpha=0.5, label='Download Real (Alvo)')\n",
    "    line_pred, = ax1.plot([], [], 'r-', lw=2, label='Previs√£o do Modelo')\n",
    "    ax1.set_title('Gr√°fico 1: Previs√£o vs. Real'); ax1.set_xlabel('Passo de Tempo'); ax1.set_ylabel('Download (bps)'); ax1.legend(); ax1.grid(True)\n",
    "    ax1.set_xlim(0, len(y)) # Deixa o Y se ajustar dinamicamente\n",
    "\n",
    "    line_erro, = ax2.plot([], [], '-', color='orange', lw=2)\n",
    "    ax2.set_title('Gr√°fico 2: Erro da Previs√£o'); ax2.set_xlabel('Passo de Tempo'); ax2.set_ylabel('Erro (bps)'); ax2.grid(True); ax2.set_xlim(0, len(y)); ax2.axhline(0, color='black', lw=1, linestyle='--')\n",
    "    \n",
    "    labels_coeficientes = ['c0(Intercepto)', 'c1(D[n])', 'c2(L_D[n])', 'c3(U[n])', 'c4(L_U[n])']\n",
    "    lines_coeffs = [ax3.plot([], [], lw=2, label=label)[0] for label in labels_coeficientes]\n",
    "    ax3.set_title('Gr√°fico 3: Converg√™ncia dos Coeficientes'); ax3.set_xlabel('Passo de Tempo'); ax3.set_ylabel('Valor do Coeficiente'); ax3.legend(); ax3.grid(True)\n",
    "    ax3.set_xlim(0, len(y))\n",
    "\n",
    "    ax4.axis('off'); ax4.set_title('Estado Atual'); tabela_texto = ax4.text(0.05, 0.95, '', fontsize=9, fontfamily='monospace', va='top')\n",
    "\n",
    "    # 4. Fun√ß√£o que desenha cada frame da anima√ß√£o\n",
    "    def animar(frame):\n",
    "        x_n, y_n = X[frame, :], y[frame]\n",
    "        previsao = filtro.predict(x_n)\n",
    "        previsoes_online.append(previsao)\n",
    "        historico_erro.append(y_n - previsao)\n",
    "        filtro.update(x_n, y_n)\n",
    "        historico_coeficientes.append(filtro.theta.copy())\n",
    "\n",
    "        line_pred.set_data(range(len(previsoes_online)), previsoes_online)\n",
    "        line_erro.set_data(range(len(historico_erro)), historico_erro)\n",
    "        \n",
    "        df_coeffs = pd.DataFrame(historico_coeficientes)\n",
    "        for i, line in enumerate(lines_coeffs):\n",
    "            line.set_data(range(len(df_coeffs)), df_coeffs.iloc[:, i])\n",
    "        \n",
    "        # --- AJUSTE 1: Controlar a escala do Gr√°fico de Erro ---\n",
    "        if frame > 10:\n",
    "            erro_visivel = np.array(historico_erro)\n",
    "            # Foca nos 98% centrais dos dados de erro para ignorar picos extremos\n",
    "            lim_inf_erro = np.percentile(erro_visivel, 1)\n",
    "            lim_sup_erro = np.percentile(erro_visivel, 99)\n",
    "            margem_erro = (lim_sup_erro - lim_inf_erro) * 0.1\n",
    "            ax2.set_ylim(lim_inf_erro - margem_erro, lim_sup_erro + margem_erro)\n",
    "            \n",
    "        # --- AJUSTE 2: Controlar a escala do Gr√°fico de Coeficientes ---\n",
    "        if frame > 10:\n",
    "            df_coeffs_visivel = df_coeffs.iloc[5:] # Ignora os primeiros 5 passos\n",
    "            lim_inf_coeff = df_coeffs_visivel.min().min()\n",
    "            lim_sup_coeff = df_coeffs_visivel.max().max()\n",
    "            margem_coeff = (lim_sup_coeff - lim_inf_coeff) * 0.1\n",
    "            ax3.set_ylim(lim_inf_coeff - margem_coeff, lim_sup_coeff + margem_coeff)\n",
    "\n",
    "        # --- AJUSTE 3: Ignorar previs√µes iniciais na escala do Gr√°fico Principal ---\n",
    "        if frame > 20: # Come√ßa a ajustar a escala do gr√°fico principal ap√≥s 20 passos\n",
    "            y_visivel = y[:frame+1]\n",
    "            pred_visivel = previsoes_online[20:] # Ignora as 20 primeiras previs√µes para a escala\n",
    "            min_val = min(np.min(y_visivel), np.min(pred_visivel))\n",
    "            max_val = max(np.max(y_visivel), np.max(pred_visivel))\n",
    "            margem = (max_val - min_val) * 0.1\n",
    "            ax1.set_ylim(min_val - margem, max_val + margem)\n",
    "        \n",
    "        texto = f\"Passo: {frame+1}/{len(y)}\\n\\nErro Atual: {historico_erro[-1]:,.2f}\\n\\nCoeficientes:\\n\"\n",
    "        for i, c in enumerate(filtro.theta): texto += f\" {labels_coeficientes[i]:<15} = {c:10.6f}\\n\"\n",
    "        tabela_texto.set_text(texto)\n",
    "        \n",
    "        return line_pred, line_erro, *lines_coeffs, tabela_texto\n",
    "\n",
    "    # 5. Cria e Salva a Anima√ß√£o\n",
    "    print(\"Criando a anima√ß√£o... Isso pode levar alguns minutos.\")\n",
    "    ani = animation.FuncAnimation(fig, animar, frames=len(y), blit=False, interval=50) # blit=False √© mais robusto para eixos din√¢micos\n",
    "    nome_arquivo = f\"animacao_{mac_alvo.replace(':', '')}_{server_alvo}.mp4\"\n",
    "    \n",
    "    try:\n",
    "        ani.save(nome_arquivo, writer='ffmpeg', dpi=150)\n",
    "        print(f\"\\n‚úÖ Anima√ß√£o '{nome_arquivo}' salva com sucesso!\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"\\n‚ùå ERRO: `ffmpeg` n√£o encontrado. N√£o foi poss√≠vel salvar o v√≠deo.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå ERRO ao salvar a anima√ß√£o: {e}\")\n",
    "    \n",
    "    plt.close(fig)\n",
    "    return ani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d804946d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================\n",
    "# BLOCO DE EXECU√á√ÉO: ESCOLHA O PAR E GERE O V√çDEO\n",
    "# ==================================================================\n",
    "\"\"\"\n",
    "Pares interessantes para an√°lise:\n",
    "'dc:a6:32:6b:9a:da', '200.159.254.239' feito e bom\n",
    "'24:2f:d0:bc:6d:01', '200.159.254.239' feito e ruim\n",
    "'dc:a6:32:6b:9a:da', '177.136.80.203' \n",
    "'dc:a6:32:6b:9a:da', '200.123.198.165'\n",
    "'dc:a6:32:6b:9c:a8', '200.159.254.239' feito e ruim\n",
    "'e4:5f:01:36:10:3e', '200.159.254.239' feito e ruim\n",
    "'e4:5f:01:8e:52:7a', '177.136.80.203'\n",
    "'e4:5f:01:8e:52:7a', '177.136.80.216'\n",
    "'e4:5f:01:8e:52:7a', '200.159.254.239' feito e ruim\n",
    "'e4:5f:01:b4:bb:d4', '200.123.198.139'\n",
    "'e4:5f:01:b4:bb:d4', '200.159.254.239' feito e ruim\n",
    "\"\"\"\n",
    "# Escolha um dos pares que voc√™ tem nos seus dados\n",
    "MAC_PARA_ANALISAR = 'e4:5f:01:b4:bb:d4' # Substitua pelo MAC que quiser\n",
    "SERVER_PARA_ANALISAR = '200.123.198.139' # Substitua pelo Servidor que quiser\n",
    "\n",
    "# Chama a fun√ß√£o para gerar a anima√ß√£o para o par escolhido\n",
    "# Usamos o df_limpo, que n√£o tem os outliers\n",
    "animacao_resultado = gerar_animacao_rls(df, MAC_PARA_ANALISAR, SERVER_PARA_ANALISAR)\n",
    "\n",
    "# (Opcional) Para exibir a anima√ß√£o diretamente no Jupyter Notebook\n",
    "#HTML(animacao_resultado.to_jshtml())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".matcomp2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
